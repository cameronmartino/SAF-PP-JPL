{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import qiime2 as q2\n",
    "from biom import Table\n",
    "from skbio import TreeNode\n",
    "from biom import load_table\n",
    "\n",
    "def subset_match(table, metadata):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function matches table & metdata\n",
    "    subsets based on the shared samples.\n",
    "    \"\"\"\n",
    "    \n",
    "    # match samples\n",
    "    subset = set(table.ids()) & set(metadata.index)\n",
    "    # filter samples\n",
    "    table = table.filter(subset)\n",
    "    # reindex metadata\n",
    "    metadata = metadata.reindex(table.ids())\n",
    "    # make sure no zero sum features\n",
    "    keep = table.ids('observation')[table.sum('observation') > 0]\n",
    "    table = table.filter(keep, axis='observation')\n",
    "    # make QIIME2 type\n",
    "    table = q2.Artifact.import_data('FeatureTable[Frequency]',\n",
    "                                    table)\n",
    "    metadata = q2.Metadata(metadata)\n",
    "    # return to save\n",
    "    return table, metadata\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34737 x 410 <class 'biom.table.Table'> with 74409 nonzero entries (0% dense)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load tree\n",
    "q2tree = q2.Artifact.import_data('Phylogeny[Rooted]',\n",
    "                                 '../data/16S/83714_insertion_tree.relabelled.tre')\n",
    "tree = q2tree.view(TreeNode)\n",
    "# get table\n",
    "bt = load_table('../data/16S/83714_27262_analysis_16S_DeblurReferencephylogenyforSEPPGreengenes138BIOMreferencehitbiomTrimminglength150_insertion_filter.biom')\n",
    "seqs_ = [node.name for node in tree.tips()]\n",
    "shared_ = list(set(seqs_) & set(bt.ids('observation')))\n",
    "bt = bt.filter(shared_ , axis='observation')\n",
    "# get mf\n",
    "qiita_drop = ['dna_extracted','physical_specimen_remaining']\n",
    "qiita_rename = {'time_numberical':'time_numerical'}\n",
    "mf = pd.read_csv('../data/16S/27262_27262_analysis_mapping.txt',\n",
    "                 sep='\\t', index_col=0).drop(qiita_drop, axis=1)\n",
    "mf = mf[mf.title.isin(['SAF_cleanroom', 'JPL_Project2'])]\n",
    "mf = mf.rename(qiita_rename, axis=1)\n",
    "# ensure matched \n",
    "shared_ = set(mf.index) & set(bt.ids())\n",
    "mf = mf.reindex(shared_)\n",
    "bt = bt.filter(shared_)\n",
    "# make sure no zero sum features\n",
    "keep = bt.ids('observation')[bt.sum('observation') > 0]\n",
    "bt = bt.filter(keep, axis='observation')\n",
    "# check\n",
    "if len(set(bt.ids()) - set(mf.index)) != 0:\n",
    "    raise ValueError('Some samples in metadata not in table')\n",
    "if len(set(mf.index) - set(bt.ids())) != 0:\n",
    "    raise ValueError('Some samples in table not in metadata')\n",
    "# add x/y metdata\n",
    "location_x_y = pd.read_csv('../data/16S/location-x-y-z-map.csv',\n",
    "                           index_col='Location_new_SAF')\n",
    "mf['jpl_x'] = [location_x_y.loc[v,'x']\n",
    "               if v in location_x_y.index else np.nan\n",
    "               for v in mf.jpl_location_area ]\n",
    "mf['jpl_y'] = [location_x_y.loc[v,'y']\n",
    "               if v in location_x_y.index else np.nan\n",
    "               for v in mf.jpl_location_area ]\n",
    "# import all\n",
    "q2bt = q2.Artifact.import_data('FeatureTable[Frequency]', bt)\n",
    "q2mf = q2.Metadata(mf)\n",
    "# save\n",
    "q2bt.save('../data/16S/all-table.qza')\n",
    "q2mf.save('../data/16S/all-metadata.qza')\n",
    "q2tree.save('../data/16S/insertion-tree.qza')\n",
    "bt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31183 x 230 <class 'biom.table.Table'> with 63703 nonzero entries (0% dense)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# jpl2 data only\n",
    "mf = mf[mf.qiita_study_id.isin(['10849'])]\n",
    "# get subset\n",
    "q2bt, q2mf = subset_match(bt.copy(), mf.copy())\n",
    "# save\n",
    "q2bt.save('../data/16S/10849-only-table.qza')\n",
    "q2mf.save('../data/16S/10849-only-metadata.qza')\n",
    "bt = q2bt.view(Table)\n",
    "bt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the set of all rep-seqs\n",
    "seqs_ = q2bt.view(Table).ids('observation')\n",
    "seqs_ = '\\n'.join(['>'+i+'\\n'+i for i in seqs_])\n",
    "f = open(\"../data/16S/rep-seqs.fa\", \"w\")\n",
    "f.write(seqs_)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mImported ../data/16S/rep-seqs.fa as DNASequencesDirectoryFormat to ../data/16S/rep-seqs.qza\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "# import the rep-seqs\n",
    "!qiime tools import \\\n",
    "    --input-path ../data/16S/rep-seqs.fa\\\n",
    "    --output-path ../data/16S/rep-seqs.qza\\\n",
    "    --type 'FeatureData[Sequence]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mSaved FeatureData[Taxonomy] to: ../data/16S/taxonomy.qza\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "# run taxonomic classification (run on cluster - big compute step)\n",
    "!qiime feature-classifier classify-sklearn \\\n",
    "  --i-classifier ../data/16S/gg-13-8-99-515-806-nb-classifier.qza \\\n",
    "  --i-reads ../data/16S/rep-seqs.qza \\\n",
    "  --o-classification ../data/16S/taxonomy.qza\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "q2tax = q2.Artifact.load('../data/16S/taxonomy.qza')\n",
    "q2tax = q2tax.view(q2.Metadata)\n",
    "taxdf = q2tax.to_dataframe()\n",
    "taxdf_split = taxdf.Taxon.str.split(';', expand=True)\n",
    "taxdf_split.columns = ['kingdom','phylum','class',\n",
    "                       'order','family','genus','sp.']\n",
    "taxdf = pd.concat([taxdf, taxdf_split], axis=1)\n",
    "q2tax = q2.Metadata(taxdf)\n",
    "q2tax.save('../data/16S/all-taxonomy.qza')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create matched data splits \n",
    "\n",
    "path = '../data/16S/data-subsets'\n",
    "pma_map = {'TRUE':'pma-treatment',\n",
    "           'FALSE':'no-pma-treatment'}\n",
    "cntrl_map = {'0':'rooms-only',\n",
    "             '1':'controls-only'}\n",
    "\n",
    "# pma and non-pma treated\n",
    "for pma_type, pma_df in mf.groupby('jpl_pma'):\n",
    "    # get subset\n",
    "    pma_tbl_subset, pma_mf_subset = subset_match(bt.copy(),\n",
    "                                                 pma_df.copy())\n",
    "    # save\n",
    "    name_pma = pma_map[pma_type]\n",
    "    pma_tbl_subset.save(os.path.join(path, '-'.join([name_pma, 'table.qza'])))\n",
    "    pma_mf_subset.save(os.path.join(path, '-'.join([name_pma, 'metadata.qza'])))\n",
    "\n",
    "    # control and non-control\n",
    "    for cntrl_type, cntrl_df in pma_df.groupby('jpl_controltype_0_1'):\n",
    "        # get subset\n",
    "        cntrl_tbl_subset, cntrl_mf_subset = subset_match(bt.copy(),\n",
    "                                                         cntrl_df.copy())   \n",
    "        # save\n",
    "        name_cntrl = cntrl_map[cntrl_type]\n",
    "        cntrl_tbl_subset.save(os.path.join(path, '-'.join([name_pma,\n",
    "                                                           name_cntrl,\n",
    "                                                           'table.qza'])))\n",
    "        cntrl_mf_subset.save(os.path.join(path, '-'.join([name_pma,\n",
    "                                                          name_cntrl,\n",
    "                                                          'metadata.qza'])))\n",
    "\n",
    "        # by time-ordered\n",
    "        for t_type, t_df in cntrl_df.groupby('time_numerical'):\n",
    "            # get subset\n",
    "            t_tbl_subset, t_mf_subset = subset_match(bt.copy(),\n",
    "                                                     t_df.copy())   \n",
    "            # save\n",
    "            name_cntrl = cntrl_map[cntrl_type]\n",
    "            t_tbl_subset.save(os.path.join(path, '-'.join([name_pma,\n",
    "                                                           name_cntrl,\n",
    "                                                           t_type,\n",
    "                                                           'table.qza'])))\n",
    "            t_mf_subset.save(os.path.join(path, '-'.join([name_pma,\n",
    "                                                          name_cntrl,\n",
    "                                                          t_type,\n",
    "                                                          'metadata.qza'])))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
